

final/
│
├── data/
│   ├── raw/                  # Données brutes, non transformées
│   │   ├── creditcard.csv    # Jeu de données original
│   │   
│   ├── processed/            # Données après prétraitement
│       └── smote_data.csv    # Données équilibrées avec SMOTE
|      └── data_tst.csv 
│
├── notebooks/
│   ├── 01_data_exploration.ipynb  # Exploration initiale des données
│   ├── 02_data_preprocessing.ipynb # Préparation et équilibrage des données
│   ├── 03_model_training.ipynb    # Entraînement des modèles
│   ├── 04_model_evaluation.ipynb  # Évaluation et visualisation des résultats     
|
├── scripts/                  # Scripts Python réutilisables pour chaque étape
│   ├── data_preprocessing.py   # Scripts pour le prétraitement des données
│   ├── smote_balancing.py      # Script pour appliquer SMOTE
│   ├── model_training.py       # Script pour entraîner les modèles
│   ├── model_evaluation.py     # Script pour l'évaluation des modèles
│
├── models/                   # Contient les modèles entraînés et leurs paramètres
│   ├── logistic_model.pkl      # Modèle sauvegardé (Logistic Regression)
│   ├── decision_tree_model.pkl # Modèle sauvegardé (Decision Tree)
│   ├── random_forest_model.pkl # Modèle sauvegardé (Random Forest)
│
├── results/
│   ├── figures/                # Graphiques (matrices de confusion, courbes ROC, etc.)
│   ├── logs/                   # Fichiers de logs des modèles et hyperparamètres
│   └── reports/                # Rapports finaux des modèles
│
├── requirements.txt            # Liste des bibliothèques Python nécessaires
├── README.md                   # Documentation générale du projet
└── main.py 

Explication de l'arborescence :
1. data/

    raw/ : Contient les données originales non modifiées, pour garantir qu’une version brute est toujours disponible.
        creditcard.csv : Jeu de données original.
    processed/ : Contient les données transformées après les étapes de prétraitement.
        smote_data.csv : Données équilibrées après application de SMOTE.
        data_tst.csv : Jeu de données de test, potentiellement séparé manuellement ou généré automatiquement.

2. notebooks/

    Contient les notebooks qui documentent et présentent chaque étape du projet avec du code, des visualisations, et des analyses.
        01_data_exploration.ipynb : Analyse exploratoire des données (statistiques descriptives, visualisations).
        02_data_preprocessing.ipynb : Prétraitement des données (nettoyage, équilibrage).
        03_model_training.ipynb : Entraînement des modèles (avec tests et réglages des hyperparamètres).
        04_model_evaluation.ipynb : Analyse des performances des modèles (métriques et courbes).

3. scripts/

    Scripts Python qui permettent d’automatiser chaque tâche du pipeline, idéal pour industrialiser le projet.
        data_preprocessing.py : Nettoyage et normalisation des données.
        smote_balancing.py : Application de SMOTE pour équilibrer les classes.
        model_training.py : Entraînement des modèles (avec enregistrement des modèles entraînés).
        model_evaluation.py : Évaluation et comparaison des performances.

4. models/

    Contient les fichiers de modèles sauvegardés au format pkl, prêts à être réutilisés ou déployés.
        logistic_model.pkl : Modèle entraîné avec régression logistique.
        decision_tree_model.pkl : Modèle basé sur les arbres de décision.
        random_forest_model.pkl : Modèle entraîné avec une forêt aléatoire.

5. results/

    Centralise les résultats et les logs pour analyse et reporting.
        figures/ : Visualisations générées (matrices de confusion, courbes ROC, etc.).
        logs/ : Fichiers de log des modèles, contenant les hyperparamètres et les résultats intermédiaires.
        reports/ : Rapports finaux consolidant les résultats et conclusions.

6. requirements.txt

    Liste des bibliothèques Python nécessaires à l’exécution du projet, par exemple :

    pandas
    numpy
    matplotlib
    seaborn
    scikit-learn
    imbalanced-learn

7. README.md

    Document qui explique :
        L’objectif du projet.
        Les étapes principales.
        Comment exécuter le projet.
        Les résultats attendus.

8. main.py

    Script principal pour exécuter l’ensemble du pipeline (prétraitement, entraînement, évaluation). Il regroupe tous les scripts et automatise le processus.