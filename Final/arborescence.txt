

final/
│
├── data/
│   
├── notebooks/
│   ├── 01_data_exploration.ipynb  # Exploration initiale des données
│   ├── 02_data_preprocessing.ipynb # Préparation et équilibrage des données
│   ├── 03_model_training.ipynb    # Entraînement des modèles
│   └──04_model_evaluation.ipynb  # Évaluation et visualisation des résultats     
|
├── scripts/                  # Scripts Python réutilisables pour chaque étape
|   ├── data_exploration.py
│   ├── data_preprocessing.py   # Scripts pour le prétraitement des données
│   ├── smote_balancing.py      # Script pour appliquer SMOTE
│   ├── model_training.py       # Script pour entraîner les modèles
│   ├── model_evaluation.py     # Script pour l'évaluation des modèles
|   └── main.py 
│
├── models/                   # Contient les modèles entraînés et leurs paramètres
│   ├── logistic_model.pkl      # Modèle sauvegardé (Logistic Regression)
│   ├── decision_tree_model.pkl # Modèle sauvegardé (Decision Tree)
│   └── random_forest_model.pkl # Modèle sauvegardé (Random Forest)
│
├── results/
│   ├── figures/                # Graphiques (courbes ROC, etc.)
│   └── reports/                # Rapports finaux des modèles et comparaison
│
├── requirements.txt            # Liste des bibliothèques Python nécessaires
├── README.md                   # Documentation générale du projet


Explication de l'arborescence :
1. data/
2. notebooks/
    Contient les notebooks qui documentent et présentent chaque étape du projet avec du code, des visualisations, et des analyses.
        01_data_exploration.ipynb : Analyse exploratoire des données (statistiques descriptives, visualisations).
        02_data_preprocessing.ipynb : Prétraitement des données (nettoyage, équilibrage).
        03_model_training.ipynb : Entraînement des modèles (avec tests et réglages des hyperparamètres).
        04_model_evaluation.ipynb : Analyse des performances des modèles (métriques et courbes).

3. scripts/
    data_exploration.py: Script pour l'exploration des données (chargement, visualisation, analyse initiale).
    data_preprocessing.py : Ce script contient les étapes de prétraitement des données (nettoyage, transformation, etc.).
    smote_balancing.py : Contient le code pour appliquer l'algorithme SMOTE afin de traiter le déséquilibre des classes dans les données.
    model_training.py : Script qui entraîne les modèles de machine learning.
    model_evaluation.py: Ce script évalue les performances des modèles.
    main.py : Le script principal du projet qui orchestre l'exécution des autres scripts dans l'ordre logique (par exemple, chargement des données, prétraitement, entraînement des modèles, et évaluation). Il sert à automatiser l'ensemble du pipeline.

4. models/

    Contient les fichiers de modèles sauvegardés au format pkl, prêts à être réutilisés ou déployés.
        logistic_model.pkl : Modèle entraîné avec régression logistique.
        decision_tree_model.pkl : Modèle basé sur les arbres de décision.
        random_forest_model.pkl : Modèle entraîné avec une forêt aléatoire.

5. results/

    Centralise les résultats et les logs pour analyse et reporting.
        figures/ : Visualisations générées (matrices de confusion, courbes ROC, etc.).
        logs/ : Fichiers de log des modèles, contenant les hyperparamètres et les résultats intermédiaires.
        reports/ : Rapports finaux consolidant les résultats et conclusions.

6. requirements.txt

    Liste des bibliothèques Python nécessaires à l’exécution du projet, par exemple :

    pandas
    numpy
    matplotlib
    seaborn
    scikit-learn
    imbalanced-learn

7. README.md

    Document qui explique :
        L’objectif du projet.
        Les étapes principales.
        Comment exécuter le projet.
        Les résultats attendus.
